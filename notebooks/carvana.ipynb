{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dc6951f-2030-460f-9ba5-f25a4e405703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import override"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c52e387c-8dac-4ced-8c6e-457d266f20de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import override\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(2025-7-23)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256fe1ee-3bcb-4a03-a4f5-3f09be50f5f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "fe147e3d-adbd-4064-92d6-c2df43c75470",
   "metadata": {},
   "source": [
    "cars = np.unique([_.split('_')[0] for _ in os.listdir(r\"D:/carvana/\")]) # harvest the base names of the cars without the augmentation suffixes\n",
    "images = np.array(os.listdir(r\"D:/carvana/\"))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "628d2ed4-a4d9-4459-b741-58b9f55a3740",
   "metadata": {},
   "source": [
    "images.size, cars.size"
   ]
  },
  {
   "cell_type": "raw",
   "id": "424dd1be-949b-4152-9f2a-ba88d9293629",
   "metadata": {},
   "source": [
    "# pick 100 random cars\n",
    "chosen = np.random.choice(cars, size=100, replace=False)\n",
    "# move them to a new folder\n",
    "chosen_images = np.array([fname for car in chosen for fname in images if fname.startswith(car)])\n",
    "# os.mkdir(r\"D:/python/carvana\")\n",
    "for file in chosen_images:\n",
    "    os.rename(src=f\"D:/carvana/{file}\", dst=f\"D:/python/carvana/{file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bbf892c0-81ff-4d7c-b356-0d08ae4cbf98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7874ef4-1d11-46de-b1b1-a0a0e4c44d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['8a34d46ec604_16.jpg', '74438e264e85_03.jpg',\n",
       "       '0dfde35f5c87_04.jpg', 'd9df232dc92c_10.jpg',\n",
       "       '46562684485a_16.jpg', '21c783b9841b_15.jpg',\n",
       "       'ae83ca58bb60_08.jpg', 'df74648c7553_11.jpg',\n",
       "       'b929b3a41d2e_15.jpg', 'b66c26e01b3f_07.jpg',\n",
       "       '292ce2c1c76b_13.jpg', 'fe0acb1321be_09.jpg',\n",
       "       'e8c01181f5e6_12.jpg', 'e9113fe5e69d_12.jpg',\n",
       "       '047df42a3f14_05.jpg', '16e8a5e36d36_16.jpg',\n",
       "       '87a4a64b3632_14.jpg', '9e139de2da5d_08.jpg',\n",
       "       '94872c4309c8_04.jpg', '3bfff4279409_05.jpg',\n",
       "       'bc2bd280d9b8_16.jpg', '1556fb3462b8_09.jpg',\n",
       "       'ae3ee849ed63_03.jpg', '3b69d6995ace_08.jpg',\n",
       "       '754eed53c22b_07.jpg', 'c6dfca36ecfc_01.jpg',\n",
       "       '90bdde690e23_08.jpg', '5b25e7d531b2_01.jpg',\n",
       "       'd465eff90a85_16.jpg', 'c7f510bbfb1d_09.jpg',\n",
       "       'ff190ce147ac_07.jpg', 'a9886f0dda80_10.jpg',\n",
       "       '7e097d195756_14.jpg', 'a715500c187f_04.jpg',\n",
       "       '9da7e05d7982_02.jpg', 'bbecfb9145d8_03.jpg',\n",
       "       'e32c4ab15d7f_08.jpg', 'af89f7cd4e98_03.jpg',\n",
       "       'a156a67a20d6_07.jpg', 'a866f408dee1_12.jpg',\n",
       "       'd3c68c48cd58_07.jpg', '595695714e9e_04.jpg',\n",
       "       '2a16952ab12a_08.jpg', '5e00331e6f84_02.jpg',\n",
       "       'fcd988291d6e_12.jpg', 'e9a71b5df96b_03.jpg',\n",
       "       'c2ea77719a08_08.jpg', '8152dc20ced1_09.jpg',\n",
       "       '2a745364fff4_01.jpg', 'a72287b71a45_12.jpg',\n",
       "       '754eed53c22b_12.jpg', '916b4ac4c315_03.jpg',\n",
       "       'afdaeda2fad1_05.jpg', 'f87b4dcad87b_14.jpg',\n",
       "       '3004d685e6a1_04.jpg', 'ddb276e6fc3a_04.jpg',\n",
       "       'b5fc63c5f217_12.jpg', '869491d91826_14.jpg',\n",
       "       'b03f87aa49f5_06.jpg', '42e7cf9bacd3_16.jpg',\n",
       "       '252c6ab0d70c_11.jpg', '3a9724b60ca7_08.jpg',\n",
       "       '5f7a1f283880_01.jpg', '37002b578904_08.jpg',\n",
       "       '6eb5839ff3b7_05.jpg', 'deb2241b5d76_10.jpg',\n",
       "       '3e2de0e89167_08.jpg', 'e1c9f08b614f_01.jpg',\n",
       "       '8d9024752304_09.jpg', '7ce2c18dbcac_05.jpg',\n",
       "       '2abd66d54547_12.jpg', '73c33e6ab101_14.jpg',\n",
       "       '27f5a3f74a2e_14.jpg', '6039fc72a3cd_15.jpg',\n",
       "       'b3d8e1c6b4dd_04.jpg', '9065ed21f001_15.jpg',\n",
       "       'a43734ce9e00_06.jpg', '0257715df161_12.jpg',\n",
       "       '02c3d72a5c57_11.jpg', '4c324e1cd6ac_02.jpg',\n",
       "       'a1219f5e1da1_07.jpg', 'f8719a37cd80_16.jpg',\n",
       "       'e8e429e46da5_03.jpg', '4566d0394275_02.jpg',\n",
       "       '590d0721458e_10.jpg', 'a0822fd77d05_09.jpg',\n",
       "       '814a9dbe9376_16.jpg', 'b4d7d7e8edcc_05.jpg',\n",
       "       'c84f576abfdc_04.jpg', 'fd3735bcd142_07.jpg',\n",
       "       'e2c6199beba7_14.jpg', 'b3e260f73c07_10.jpg',\n",
       "       'be25a7cd69d0_13.jpg', '475f6eb4db87_03.jpg',\n",
       "       'd8531ba0155c_10.jpg', 'a716083015fa_05.jpg',\n",
       "       'c90d652fd576_15.jpg', 'a68581b6f306_04.jpg',\n",
       "       'c324d303e7d1_02.jpg', '8f72cdba1cbf_11.jpg'], dtype='<U19')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just pick 100 images of cars (nonrepetitively)\n",
    "\n",
    "for image in np.random.choice(os.listdir(r\"D:/carvana/\"), size=100, replace=False):\n",
    "    os.rename(src=f\"D:/carvana/{\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe910172-29ed-4118-bff7-c7e56590c1cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea59fa8-6fb1-4a1c-b2d5-80c2fd496e59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a41ec86e-d6b0-4f64-851c-e8fd1988a1a5",
   "metadata": {},
   "source": [
    "# ___UNet___\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e68b02-7d05-41cd-a156-8aebd23a6d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"\n",
    "    (convolution => [BN] => ReLU) * 2\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels: int, out_channels: int, mid_channels: int | None = None) -> None:\n",
    "        super(DoubleConv, self).__init__()  # type: ignore\n",
    "\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "\n",
    "        self.double_conv = nn.Sequential(\n",
    "            # first set\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # second set\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    @override\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"\n",
    "    Downscaling with maxpool then double convolution\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels: int, out_channels: int) -> None:\n",
    "        super(Down, self).__init__()  # type: ignore\n",
    "        self.maxpool_conv = nn.Sequential(nn.MaxPool2d(2), DoubleConv(in_channels, out_channels))\n",
    "\n",
    "    @override\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"\n",
    "    Upscaling then double convolution\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels: int, out_channels: int, bilinear: bool = True) -> None:\n",
    "        super(Up, self).__init__()  # type: ignore\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    @override\n",
    "    def forward(self, x1: torch.Tensor, x2: torch.Tensor) -> torch.Tensor:\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = pad(x1, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2])\n",
    "        # if you have padding issues, see\n",
    "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int) -> None:\n",
    "        super(OutConv, self).__init__()  # type: ignore\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    @override\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    \"\"\" \"\"\"\n",
    "\n",
    "    def __init__(self, n_channels: int, n_classes: int, bilinear: bool = False) -> None:\n",
    "        super(UNet, self).__init__()  # type: ignore\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "        factor: int = 2 if bilinear else 1\n",
    "\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "\n",
    "        self.down4 = Down(512, 1024 // factor)\n",
    "        self.up1 = Up(1024, 512 // factor, bilinear)\n",
    "        self.up2 = Up(512, 256 // factor, bilinear)\n",
    "        self.up3 = Up(256, 128 // factor, bilinear)\n",
    "        self.up4 = Up(128, 64, bilinear)\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "\n",
    "    @override\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits\n",
    "\n",
    "    def use_checkpointing(self) -> None:\n",
    "        self.inc = torch.utils.checkpoint(self.inc)\n",
    "        self.down1 = torch.utils.checkpoint(self.down1)\n",
    "        self.down2 = torch.utils.checkpoint(self.down2)\n",
    "        self.down3 = torch.utils.checkpoint(self.down3)\n",
    "        self.down4 = torch.utils.checkpoint(self.down4)\n",
    "        self.up1 = torch.utils.checkpoint(self.up1)\n",
    "        self.up2 = torch.utils.checkpoint(self.up2)\n",
    "        self.up3 = torch.utils.checkpoint(self.up3)\n",
    "        self.up4 = torch.utils.checkpoint(self.up4)\n",
    "        self.outc = torch.utils.checkpoint(self.outc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3390bc4-a66c-4eb7-a761-3600603f9160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7750c22-7987-449a-9521-1857088919b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209a21c6-2df2-4114-91d0-8cf6cd06422c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15281f61-ad92-40db-9bf0-b182241057a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNet(n_channels=3, n_classes=1)\n",
    "model.to(device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
